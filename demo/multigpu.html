

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Multi-GPU Training &mdash; MinkowskiEngine 0.3.3 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="PointNet" href="pointnet.html" />
    <link rel="prev" title="Working with Pytorch Layers" href="interop.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> MinkowskiEngine
          

          
          </a>

          
            
            
              <div class="version">
                0.3.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Minkowski Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../convolution_on_sparse.html">Convolution on a Sparse Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../terminology.html">Definitions and Terminology</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorial/sparse_tensor_basic.html">Sparse Tensor Basics</a></li>
</ul>
<p class="caption"><span class="caption-text">Demos</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="training.html">Training Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="modelnet40.html">ModelNet40 Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="segmentation.html">Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="interop.html">Working with Pytorch Layers</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Multi-GPU Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#synchronized-batch-norm">Synchronized Batch Norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loading-multiple-batches">Loading multiple batches</a></li>
<li class="toctree-l2"><a class="reference internal" href="#copying-weights-to-devices">Copying weights to devices</a></li>
<li class="toctree-l2"><a class="reference internal" href="#applying-replicas-to-all-batches">Applying replicas to all batches</a></li>
<li class="toctree-l2"><a class="reference internal" href="#speedup-experiments">Speedup Experiments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#analysis">Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pointnet.html">PointNet</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../sparse_tensor.html">SparseTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../convolution.html">MinkowskiConvolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pooling.html">MinkowskiPooling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../broadcast.html">MinkowskiBroadcast</a></li>
<li class="toctree-l1"><a class="reference internal" href="../normalization.html">MinkowskiNormalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nonlinearity.html">MinkowskiNonlinearities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pruning.html">MinkowskiPruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../union.html">MinkowskiUnion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../coords.html">Coordinate Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">Utility Functions and Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common.html">Miscellaneous Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc.html">Miscellanea</a></li>
</ul>
<p class="caption"><span class="caption-text">Miscellanea</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../issues.html">Common Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides.html">Guidelines for Faster Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark.html">Benchmark</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MinkowskiEngine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Multi-GPU Training</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/demo/multigpu.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">

           <div itemprop="articleBody">
            
  <div class="section" id="multi-gpu-training">
<h1>Multi-GPU Training<a class="headerlink" href="#multi-gpu-training" title="Permalink to this headline">¶</a></h1>
<p>Currently, the MinkowskiEngine supports Multi-GPU training through data parallelization. In data parallelization, we have a set of mini batches that will be fed into a set of replicas of a network.</p>
<p>Let’s define a network first.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">MinkowskiEngine</span> <span class="kn">as</span> <span class="nn">ME</span>
<span class="kn">from</span> <span class="nn">examples.minkunet</span> <span class="kn">import</span> <span class="n">MinkUNet34C</span>

<span class="c1"># Copy the network to GPU</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">MinkUNet34C</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">D</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">target_device</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="synchronized-batch-norm">
<h2>Synchronized Batch Norm<a class="headerlink" href="#synchronized-batch-norm" title="Permalink to this headline">¶</a></h2>
<p>Next, we create a new network with <code class="docutils literal notranslate"><span class="pre">ME.MinkowskiSynchBatchNorm</span></code> that replaces all <code class="docutils literal notranslate"><span class="pre">ME.MinkowskiBatchNorm</span></code>. This allows the network to use the large batch size and to maintain the same performance with a single-gpu training.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Synchronized batch norm</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">ME</span><span class="o">.</span><span class="n">MinkowskiSyncBatchNorm</span><span class="o">.</span><span class="n">convert_sync_batchnorm</span><span class="p">(</span><span class="n">net</span><span class="p">);</span>
</pre></div>
</div>
<p>Next, we need to create replicas of the network and the final loss layer (if you use one).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn.parallel</span> <span class="kn">as</span> <span class="nn">parallel</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">criterions</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">.</span><span class="n">replicate</span><span class="p">(</span><span class="n">criterion</span><span class="p">,</span> <span class="n">devices</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="loading-multiple-batches">
<h2>Loading multiple batches<a class="headerlink" href="#loading-multiple-batches" title="Permalink to this headline">¶</a></h2>
<p>During training, we need a set of mini batches for each training iteration. We used a function that returns one mini batch, but you do not need to follow this pattern.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get new data</span>
<span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_devices</span><span class="p">):</span>
    <span class="n">coords</span><span class="p">,</span> <span class="n">feat</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">data_loader</span><span class="p">()</span>  <span class="o">//</span> <span class="n">parallel</span> <span class="n">data</span> <span class="n">loaders</span> <span class="n">can</span> <span class="n">be</span> <span class="n">used</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
      <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ME</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="n">coords</span><span class="o">=</span><span class="n">coords</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="section" id="copying-weights-to-devices">
<h2>Copying weights to devices<a class="headerlink" href="#copying-weights-to-devices" title="Permalink to this headline">¶</a></h2>
<p>First, we copy weights to all devices.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">replicas</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">.</span><span class="n">replicate</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">devices</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="applying-replicas-to-all-batches">
<h2>Applying replicas to all batches<a class="headerlink" href="#applying-replicas-to-all-batches" title="Permalink to this headline">¶</a></h2>
<p>Next, we feed all mini-batches to the corresponding replicas of the network on all devices. All outputs features are then fed into the loss layers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">outputs</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">.</span><span class="n">parallel_apply</span><span class="p">(</span><span class="n">replicas</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="n">devices</span><span class="p">)</span>

<span class="c1"># Extract features from the sparse tensors to use a pytorch criterion</span>
<span class="n">out_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="o">.</span><span class="n">F</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
<span class="n">losses</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">.</span><span class="n">parallel_apply</span><span class="p">(</span>
    <span class="n">criterions</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)),</span> <span class="n">devices</span><span class="o">=</span><span class="n">devices</span><span class="p">)</span>
</pre></div>
</div>
<p>Gathering all losses to the target device.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">target_device</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<p>The rest of the training such as backward, and taking a step in an optimizer is similar to single-GPU training. Please refer to the <a class="reference external" href="https://github.com/StanfordVL/MinkowskiEngine/blob/master/examples/multigpu.py">complete multi-gpu example</a> for more detail.</p>
</div>
<div class="section" id="speedup-experiments">
<h2>Speedup Experiments<a class="headerlink" href="#speedup-experiments" title="Permalink to this headline">¶</a></h2>
<p>We use various batch sizes on 4x Titan XP’s for the experiment and will divide the load to each gpu equally. For instance, with 1 GPU, each batch will have batch size 8. With 2 GPUs, we will have 4 batches for each GPU. With 4 GPUs, each GPU will have batch size 2.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th align="center">Number of GPUs</th>
<th align="center">Batch size per GPU</th>
<th align="center">Time per iteration</th>
<th align="center">Speedup (Ideal)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1 GPU</td>
<td align="center">8</td>
<td align="center">1.611 s</td>
<td align="center">x1      (x1)</td>
</tr>
<tr>
<td align="center">2 GPU</td>
<td align="center">4</td>
<td align="center">0.916 s</td>
<td align="center">x1.76   (x2)</td>
</tr>
<tr>
<td align="center">4 GPU</td>
<td align="center">2</td>
<td align="center">0.689 s</td>
<td align="center">x2.34   (x4)</td>
</tr>
</tbody>
</table><table border="1" class="docutils">
<thead>
<tr>
<th align="center">Number of GPUs</th>
<th align="center">Batch size per GPU</th>
<th align="center">Time per iteration</th>
<th align="center">Speedup (Ideal)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1 GPU</td>
<td align="center">12</td>
<td align="center">2.691 s</td>
<td align="center">x1      (x1)</td>
</tr>
<tr>
<td align="center">2 GPU</td>
<td align="center">6</td>
<td align="center">1.413 s</td>
<td align="center">x1.90   (x2)</td>
</tr>
<tr>
<td align="center">3 GPU</td>
<td align="center">4</td>
<td align="center">1.064 s</td>
<td align="center">x2.53   (x3)</td>
</tr>
<tr>
<td align="center">4 GPU</td>
<td align="center">3</td>
<td align="center">1.006 s</td>
<td align="center">x2.67   (x4)</td>
</tr>
</tbody>
</table><table border="1" class="docutils">
<thead>
<tr>
<th align="center">Number of GPUs</th>
<th align="center">Batch size per GPU</th>
<th align="center">Time per iteration</th>
<th align="center">Speedup (Ideal)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1 GPU</td>
<td align="center">16</td>
<td align="center">3.543 s</td>
<td align="center">x1      (x1)</td>
</tr>
<tr>
<td align="center">2 GPU</td>
<td align="center">8</td>
<td align="center">1.933 s</td>
<td align="center">x1.83   (x2)</td>
</tr>
<tr>
<td align="center">4 GPU</td>
<td align="center">4</td>
<td align="center">1.322 s</td>
<td align="center">x2.68   (x4)</td>
</tr>
</tbody>
</table><table border="1" class="docutils">
<thead>
<tr>
<th align="center">Number of GPUs</th>
<th align="center">Batch size per GPU</th>
<th align="center">Time per iteration</th>
<th align="center">Speedup (Ideal)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1 GPU</td>
<td align="center">18</td>
<td align="center">4.391 s</td>
<td align="center">x1      (x1)</td>
</tr>
<tr>
<td align="center">2 GPU</td>
<td align="center">9</td>
<td align="center">2.114 s</td>
<td align="center">x2.08   (x2)</td>
</tr>
<tr>
<td align="center">3 GPU</td>
<td align="center">6</td>
<td align="center">1.660 s</td>
<td align="center">x2.65   (x3)</td>
</tr>
</tbody>
</table><table border="1" class="docutils">
<thead>
<tr>
<th align="center">Number of GPUs</th>
<th align="center">Batch size per GPU</th>
<th align="center">Time per iteration</th>
<th align="center">Speedup (Ideal)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1 GPU</td>
<td align="center">20</td>
<td align="center">4.639 s</td>
<td align="center">x1      (x1)</td>
</tr>
<tr>
<td align="center">2 GPU</td>
<td align="center">10</td>
<td align="center">2.426 s</td>
<td align="center">x1.91   (x2)</td>
</tr>
<tr>
<td align="center">4 GPU</td>
<td align="center">5</td>
<td align="center">1.707 s</td>
<td align="center">x2.72   (x4)</td>
</tr>
</tbody>
</table><table border="1" class="docutils">
<thead>
<tr>
<th align="center">Number of GPUs</th>
<th align="center">Batch size per GPU</th>
<th align="center">Time per iteration</th>
<th align="center">Speedup (Ideal)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1 GPU</td>
<td align="center">21</td>
<td align="center">4.894 s</td>
<td align="center">x1      (x1)</td>
</tr>
<tr>
<td align="center">3 GPU</td>
<td align="center">7</td>
<td align="center">1.877 s</td>
<td align="center">x2.61   (x3)</td>
</tr>
</tbody>
</table></div>
<div class="section" id="analysis">
<h2>Analysis<a class="headerlink" href="#analysis" title="Permalink to this headline">¶</a></h2>
<p>We observe that the speedup is pretty modest with smaller batch sizes. However, for large batch sizes (e.g. 18 and 20), the speedup increases as the thread initialization overhead gets amortized over the large job sizes.</p>
<p>Also, in all cases, using 4 GPUs is not efficient and the speed up seems very small (x2.65 for 3-GPU with total batch size 18 vs. x2.72 for 4-GPU with total batch size 20). Thus, it is recommended to use up to 3 GPUs with large batch sizes.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th align="center">Number of GPUs</th>
<th align="center">Average Speedup (Ideal)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1 GPU</td>
<td align="center">x1      (x1)</td>
</tr>
<tr>
<td align="center">2 GPU</td>
<td align="center">x1.90   (x2)</td>
</tr>
<tr>
<td align="center">3 GPU</td>
<td align="center">x2.60   (x3)</td>
</tr>
<tr>
<td align="center">4 GPU</td>
<td align="center">x2.60   (x4)</td>
</tr>
</tbody>
</table><p>The reason for the modest speed-up is due to the heavy CPU usage. In Minkowski Engine, all sparse tensor coordinates are managed on CPU and the kernel in-out map requires significant CPU computation. Thus, for larger speed-up, it is recommended to use faster CPUs which could be a bottleneck for large point clouds.</p>
</div>
</div>


           </div>
           
          </div>
<a href="https://github.com/StanfordVL/MinkowskiEngine">
    <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub">
</a>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-43980256-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-43980256-3');
</script>


          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="pointnet.html" class="btn btn-neutral float-right" title="PointNet" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="interop.html" class="btn btn-neutral float-left" title="Working with Pytorch Layers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Chris Choy

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>