

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Convolution on a Sparse Tensor &mdash; MinkowskiEngine 0.3.3 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quick Start" href="quick_start.html" />
    <link rel="prev" title="Minkowski Engine" href="overview.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> MinkowskiEngine
          

          
          </a>

          
            
            
              <div class="version">
                0.3.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Minkowski Engine</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Convolution on a Sparse Tensor</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#sparse-tensor">Sparse Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#generalized-convolution-on-a-sparse-tensor">Generalized Convolution on a Sparse Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="terminology.html">Definitions and Terminology</a></li>
</ul>
<p class="caption"><span class="caption-text">Demos</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="demo/training.html">Training Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/modelnet40.html">ModelNet40 Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/segmentation.html">Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/interop.html">Working with Pytorch Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/multigpu.html">Multi-GPU Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/pointnet.html">PointNet</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sparse_tensor.html">SparseTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="convolution.html">MinkowskiConvolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="pooling.html">MinkowskiPooling</a></li>
<li class="toctree-l1"><a class="reference internal" href="broadcast.html">MinkowskiBroadcast</a></li>
<li class="toctree-l1"><a class="reference internal" href="normalization.html">MinkowskiNormalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="nonlinearity.html">MinkowskiNonlinearities</a></li>
<li class="toctree-l1"><a class="reference internal" href="pruning.html">MinkowskiPruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="union.html">MinkowskiUnion</a></li>
<li class="toctree-l1"><a class="reference internal" href="coords.html">Coordinate Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">Utility Functions and Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="common.html">Miscellaneous Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="misc.html">Miscellanea</a></li>
</ul>
<p class="caption"><span class="caption-text">Miscellanea</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="issues.html">Common Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="guides.html">Guidelines for Faster Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmark</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MinkowskiEngine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Convolution on a Sparse Tensor</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/convolution_on_sparse.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">

           <div itemprop="articleBody">
            
  <div class="section" id="convolution-on-a-sparse-tensor">
<h1>Convolution on a Sparse Tensor<a class="headerlink" href="#convolution-on-a-sparse-tensor" title="Permalink to this headline">¶</a></h1>
<div class="section" id="sparse-tensor">
<h2>Sparse Tensor<a class="headerlink" href="#sparse-tensor" title="Permalink to this headline">¶</a></h2>
<p>In traditional speech, text, or image data, features are extracted densely.
Thus, the most common representations of these data are vectors, matrices, and
tensors. However, for 3-dimensional scans or even higher-dimensional spaces,
such dense representations are inefficient due to the sparsity. Instead, we can
only save the non-empty part of the space as its coordinates and the associated
features. This representation is an N-dimensional extension of a sparse matrix;
thus it is known as a sparse tensor.</p>
<p>In the Minkowski Engine, we adopt the same sparse tensor for the basic data
representation and the class is provided in
<code class="xref py py-attr docutils literal notranslate"><span class="pre">MinkowskiEngine.SparseTensor</span></code>. We use the COOrdinate (COO) format to
save a sparse tensor <a class="reference external" href="http://groups.csail.mit.edu/commit/papers/2016/parker-thesis.pdf">[1]</a>. This
representation is simply a concatenation of coordinates in a matrix <span class="math notranslate nohighlight">\(C\)</span>
and associated features <span class="math notranslate nohighlight">\(F\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{C} = \begin{bmatrix}
x_1^1   &amp; x_1^2  &amp; \cdots &amp; x_1^D  &amp; b_1    \\
 \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
x_N^1   &amp; x_N^2  &amp; \cdots &amp; x_N^D  &amp; b_N
\end{bmatrix}, \; \mathbf{F} = \begin{bmatrix}
\mathbf{f}_1^T\\
\vdots\\
\mathbf{f}_N^T
\end{bmatrix}\end{split}\]</div>
<p>In the above equation, we use a <span class="math notranslate nohighlight">\(D\)</span>-dimensional space and <span class="math notranslate nohighlight">\(N\)</span>
number of points, each with the coordinate <span class="math notranslate nohighlight">\((x_i^1, x_i^1, \cdots,
x_i^D)\)</span>, and the associated feature <span class="math notranslate nohighlight">\(\mathbf{f}_i\)</span>. <span class="math notranslate nohighlight">\(b_i\)</span> indicates
the mini-batch index to disassociate instances within the same batch.
Internally, we handle the batch index as an additional spatial dimension.</p>
</div>
<div class="section" id="generalized-convolution-on-a-sparse-tensor">
<h2>Generalized Convolution on a Sparse Tensor<a class="headerlink" href="#generalized-convolution-on-a-sparse-tensor" title="Permalink to this headline">¶</a></h2>
<p>The convolution is a fundamental operation in many fields. In image perception,
the 2D convolution has achieved state-of-the-art performance in many tasks and
is proven to be the most crucial operation in AI, and computer vision research.
In this work, we adopt the sparse convolution <a class="reference external" href="https://arxiv.org/abs/1711.10275">[2]</a> and propose the generalized convolution on a sparse
tensor. We use the generalized convolution not only to the 3D
spatial axes, but also to the temporal axis, which is proven to be more
effective than recurrent neural networks (RNN) in some applications.</p>
<p>Specifically, we the generalize convolution for generic input and
output coordinates, and for arbitrary kernel shapes. The generalized convolution
encompasses not only all sparse convolutions but also the
conventional dense convolutions. Let <span class="math notranslate nohighlight">\(x^{\text{in}}_\mathbf{u} \in
\mathbb{R}^{N^\text{in}}\)</span> be an <span class="math notranslate nohighlight">\(N^\text{in}\)</span>-dimensional input feature
vector in a <span class="math notranslate nohighlight">\(D\)</span>-dimensional space at <span class="math notranslate nohighlight">\(\mathbf{u} \in \mathbb{R}^D\)</span>
(a D-dimensional coordinate), and convolution kernel weights be
<span class="math notranslate nohighlight">\(\mathbf{W} \in \mathbb{R}^{K^D \times N^\text{out} \times N^\text{in}}\)</span>.
We break down the weights into spatial weights with <span class="math notranslate nohighlight">\(K^D\)</span> matrices of
size <span class="math notranslate nohighlight">\(N^\text{out} \times N^\text{in}\)</span> as <span class="math notranslate nohighlight">\(W_\mathbf{i}\)</span> for
<span class="math notranslate nohighlight">\(|\{\mathbf{i}\}_\mathbf{i}| = K^D\)</span>. Then, the conventional dense
convolution in D-dimension is</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\text{out}}_\mathbf{u} = \sum_{\mathbf{i} \in \mathcal{V}^D(K)} W_\mathbf{i} \mathbf{x}^{\text{in}}_{\mathbf{u} + \mathbf{i}} \text{ for } \mathbf{u} \in \mathbb{Z}^D,\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{V}^D(K)\)</span> is the list of offsets in <span class="math notranslate nohighlight">\(D\)</span>-dimensional
hypercube centered at the origin. e.g. <span class="math notranslate nohighlight">\(\mathcal{V}^1(3)=\{-1, 0, 1\}\)</span>.
The generalized convolution in the following equation relaxes the above
equation.</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\text{out}}_\mathbf{u} = \sum_{\mathbf{i} \in \mathcal{N}^D(\mathbf{u}, \mathcal{C}^{\text{in}})} W_\mathbf{i} \mathbf{x}^{\text{in}}_{\mathbf{u} + \mathbf{i}} \text{ for } \mathbf{u} \in \mathcal{C}^{\text{out}}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{N}^D\)</span> is a set of offsets that define the shape of a
kernel and <span class="math notranslate nohighlight">\(\mathcal{N}^D(\mathbf{u}, \mathcal{C}^\text{in})=
\{\mathbf{i} | \mathbf{u} + \mathbf{i} \in \mathcal{C}^\text{in}, \mathbf{i}
\in \mathcal{N}^D \}\)</span> as the set of offsets from the current center,
<span class="math notranslate nohighlight">\(\mathbf{u}\)</span>, that exist in <span class="math notranslate nohighlight">\(\mathcal{C}^\text{in}\)</span>.
<span class="math notranslate nohighlight">\(\mathcal{C}^\text{in}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{C}^\text{out}\)</span> are predefined
input and output coordinates of sparse tensors. First, note that the input
coordinates and output coordinates are not necessarily the same.  Second, we
define the shape of the convolution kernel arbitrarily with
<span class="math notranslate nohighlight">\(\mathcal{N}^D\)</span>. This generalization encompasses many special cases such
as the dilated convolution and typical hypercubic kernels. Another interesting
special case is the sparse submanifold convolution when we set
<span class="math notranslate nohighlight">\(\mathcal{C}^\text{out} = \mathcal{C}^\text{in}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{N}^D
= \mathcal{V}^D(K)\)</span>. If we set <span class="math notranslate nohighlight">\(\mathcal{C}^\text{in} =
\mathcal{C}^\text{out} = \mathbb{Z}^D\)</span> and <span class="math notranslate nohighlight">\(\mathcal{N}^D =
\mathcal{V}^D(K)\)</span>, the generalized convolution on a sparse tensor becomes the conventional
dense convolution.  If we define the <span class="math notranslate nohighlight">\(\mathcal{C}^\text{in}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{C}^\text{out}\)</span> as multiples of a natural number and
<span class="math notranslate nohighlight">\(\mathcal{N}^D = \mathcal{V}^D(K)\)</span>, we have a strided dense convolution.</p>
<p>We visualize a simple 2D image convolution on a dense tensor and a sparse tensor. Note that the order of convolution on a sparse tensor is not sequential.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 48%" />
<col style="width: 52%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Dense Tensor</p></td>
<td><p>Sparse Tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="_images/conv_dense.gif"><img alt="dense" src="_images/conv_dense.gif" style="width: 100%;" /></a></p></td>
<td><p><a class="reference internal" href="_images/conv_sparse.gif"><img alt="sparse" src="_images/conv_sparse.gif" style="width: 100%;" /></a></p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p>[Photo Credit: <a class="reference external" href="https://chrischoy.org">Chris Choy</a>]</p></td>
</tr>
</tbody>
</table>
<p>To efficiently compute the convolution on a sparse tensor, we must find how each non-zero element in an input sparse tensor is mapped to the output sparse tensor. We call this mapping a kernel map <a class="reference external" href="https://arxiv.org/abs/1904.08755">[3]</a> since it defines how an input is mapped to an output through a kernel. Please refer to the <a class="reference external" href="terminology.html">terminology</a> for more details.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="http://groups.csail.mit.edu/commit/papers/2016/parker-thesis.pdf">[1] An Investigation of Sparse Tensor Formats for Tensor Libraries, 2015</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1711.10275">[2] 3D Semantic Segmentation with Submanifold Sparse Convolutional Neural Networks, CVPR’18</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1904.08755">[3] 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks, CVPR’19</a></p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
<a href="https://github.com/StanfordVL/MinkowskiEngine">
    <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub">
</a>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-43980256-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-43980256-3');
</script>


          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="quick_start.html" class="btn btn-neutral float-right" title="Quick Start" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="overview.html" class="btn btn-neutral float-left" title="Minkowski Engine" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Chris Choy

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>