

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Definitions and Terminology &mdash; MinkowskiEngine 0.4.3 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Sparse Tensor Basics" href="tutorial/sparse_tensor_basic.html" />
    <link rel="prev" title="Quick Start" href="quick_start.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MinkowskiEngine
          

          
          </a>

          
            
            
              <div class="version">
                0.4.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Minkowski Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_tensor_network.html">Sparse Tensor Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Quick Start</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Definitions and Terminology</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#sparse-tensor">Sparse Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensor-stride">Tensor Stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="#coordinate-manager">Coordinate Manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="#coordinate-key">Coordinate Key</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kernel-map">Kernel Map</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorial/sparse_tensor_basic.html">Sparse Tensor Basics</a></li>
</ul>
<p class="caption"><span class="caption-text">Demos</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="demo/training.html">Training Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/modelnet40_classification.html">ModelNet40 Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/segmentation.html">Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/sparse_tensor_reconstruction.html">3D Sparsity Pattern Reconstruction</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/interop.html">Working with Pytorch Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/multigpu.html">Multi-GPU Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/pointnet.html">PointNet</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sparse_tensor.html">SparseTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="convolution.html">MinkowskiConvolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="pooling.html">MinkowskiPooling</a></li>
<li class="toctree-l1"><a class="reference internal" href="broadcast.html">MinkowskiBroadcast</a></li>
<li class="toctree-l1"><a class="reference internal" href="normalization.html">MinkowskiNormalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="nonlinearity.html">MinkowskiNonlinearities</a></li>
<li class="toctree-l1"><a class="reference internal" href="pruning.html">MinkowskiPruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="union.html">MinkowskiUnion</a></li>
<li class="toctree-l1"><a class="reference internal" href="coords.html">Coordinate Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">Utility Functions and Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="common.html">Miscellaneous Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="misc.html">Miscellanea</a></li>
</ul>
<p class="caption"><span class="caption-text">Miscellanea</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="issues.html">Common Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="guides.html">Guidelines for Faster Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmark</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MinkowskiEngine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Definitions and Terminology</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/terminology.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">

           <div itemprop="articleBody">
            
  <div class="section" id="definitions-and-terminology">
<h1>Definitions and Terminology<a class="headerlink" href="#definitions-and-terminology" title="Permalink to this headline">¶</a></h1>
<div class="section" id="sparse-tensor">
<h2>Sparse Tensor<a class="headerlink" href="#sparse-tensor" title="Permalink to this headline">¶</a></h2>
<p>A sparse tensor is a high-dimensional extension of a sparse matrix where non-zero elements are represented as a set of indices <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> and associated values (or features) <span class="math notranslate nohighlight">\(\mathcal{F}\)</span>. We use the COOrdinate list (COO) format to save a sparse tensor <a class="reference external" href="http://groups.csail.mit.edu/commit/papers/2016/parker-thesis.pdf">[1]</a>. This representation is simply a concatenation of coordinates into a matrix <span class="math notranslate nohighlight">\(C\)</span> and associated values or features <span class="math notranslate nohighlight">\(F\)</span>. In traditional sparse tensor, indices or coordinates have to be non-negative integers, whereas, in Minkowski Engine, negative coordinates are also valid coordinates. A final sparse tensor <span class="math notranslate nohighlight">\(\mathscr{T}\)</span> with <span class="math notranslate nohighlight">\(D\)</span> dimensional coordinates is a rank-<span class="math notranslate nohighlight">\(D\)</span> tensor if features are scalars, or a rank-<span class="math notranslate nohighlight">\(D + 1\)</span> if features are vectors.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{C} = \begin{bmatrix}
x_1^1   &amp; x_1^2  &amp; \cdots &amp; x_1^D  \\
 \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_N^1   &amp; x_N^2  &amp; \cdots &amp; x_N^D
\end{bmatrix}, \; \mathbf{F} = \begin{bmatrix}
\mathbf{f}_1^T\\
\vdots\\
\mathbf{f}_N^T
\end{bmatrix}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\mathscr{T}[x^1_i,  x^2_i,  \cdots, x^D_i] = \begin{cases}
   \mathbf{f}_i \;\; &amp; \text{if} \; (x^1_i,  x^2_i, \cdots, x^D_i) \in \mathcal{C} \\
   0   \;\; &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<p>In sum, a sparse tensor consists of a set of coordinates <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> or equivalently a coordinate matrix <span class="math notranslate nohighlight">\(C \in \mathbb{Z}^{N \times D}\)</span> and associated features <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> or a feature matrix <span class="math notranslate nohighlight">\(F \in \mathbb{R}^{N \times N_F}\)</span> where <span class="math notranslate nohighlight">\(N\)</span> is the number of non-zero elements within a sparse tensor, <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the space, and <span class="math notranslate nohighlight">\(N_F\)</span> is the number of channels. The rest of the elements in a sparse tensor is 0.</p>
</div>
<div class="section" id="tensor-stride">
<h2>Tensor Stride<a class="headerlink" href="#tensor-stride" title="Permalink to this headline">¶</a></h2>
<p>A receptive field size of a neuron is defined as the maximum distance along one axis between pixels in the input image that the neuron in a layer can see. For example, if we process an image with two convolution layers with kernel size 3 and stride 2, the receptive field size after the first convolution layer is 3; and the receptive field size after the second convolution layer is 7. This is due to the fact that the second convolution layer sees the feature map that subsamples the image with the factor of 2 or stride 2. Here, the stride refers to the distance between neurons. The feature map after the first convolution has the stride size 2 and that after the second convolution has the stride size 4. Similarly, if we use transposed convolutions (deconv, upconv), we reduce the stride.</p>
<p>We define a tensor stride to be the high-dimensional counterpart of these 2D strides in the above example. When we use pooling or convolution layers with stride greater than 1, the tensor stride of the output feature map increases by the factor of the stride of the layer.</p>
</div>
<div class="section" id="coordinate-manager">
<h2>Coordinate Manager<a class="headerlink" href="#coordinate-manager" title="Permalink to this headline">¶</a></h2>
<p>Many basic operations such as convolution, pooling, etc, require finding neighbors between non-zero elements. If we use a strided convolution or pooling layer, we need to generate a new set of output coordinates that are different from the input coordinates. All these coordinate-related operations are all managed by a coordinate manager. One thing to note is that coordinate managers cache all coordinates and kernel maps as these coordinates and kernel maps are reused very frequently. For example, in many conventional neural networks, we repeat the same operations in series multiple times such as multiple residual blocks in a ResNet or a DenseNet. Thus, instead of recomputing the same coordinates and same kernel maps, a coordinate manager caches all these and reuses if it detects the same operation in the dictionary.</p>
<p>In Minkowski Engine, we create a coordinate manager when <a class="reference internal" href="source/MinkowskiEngine.html#module-MinkowskiEngine.SparseTensor" title="MinkowskiEngine.SparseTensor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">MinkowskiEngine.SparseTensor</span></code></a> is initialized. You can optionally share an existing coordinate manager with a new <a class="reference internal" href="source/MinkowskiEngine.html#module-MinkowskiEngine.SparseTensor" title="MinkowskiEngine.SparseTensor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">MinkowskiEngine.SparseTensor</span></code></a> by providing optional coordinate manager argument during initialization. You can access the coordinate manager of a sparse tensor with <code class="xref py py-attr docutils literal notranslate"><span class="pre">MinkowskiEngine.SparseTensor.coords_man</span></code>.</p>
</div>
<div class="section" id="coordinate-key">
<h2>Coordinate Key<a class="headerlink" href="#coordinate-key" title="Permalink to this headline">¶</a></h2>
<p>Within a coordinate manager, all objects are cached using an unordered map. A coordinate key is a hash key for the unordered map that caches the coordinates of sparse tensors. If two sparse tensors have the same coordinate manager and the same coordinate key, then the coordinates of the sparse tensors are identical and they share the same memory space.</p>
</div>
<div class="section" id="kernel-map">
<h2>Kernel Map<a class="headerlink" href="#kernel-map" title="Permalink to this headline">¶</a></h2>
<p>A sparse tensor consists of a set of coordinates <span class="math notranslate nohighlight">\(C \in \mathbb{Z}^{N \times D}\)</span> and associated features <span class="math notranslate nohighlight">\(F \in \mathbb{R}^{N \times N_F}\)</span> where <span class="math notranslate nohighlight">\(N\)</span> is the number of non-zero elements within a sparse tensor, <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the space, and <span class="math notranslate nohighlight">\(N_F\)</span> is the number of channels.
To find how a sparse tensor is mapped to another sparse tensor using a spatially local operations such as convolution or pooling, we need to find which coordinate in the input sparse tensor is mapped to which coordinate in the output sparse tensor.</p>
<p>We call this mapping from an input sparse tensor to an output sparse tensor a kernel map. For example, a 2D convolution with kernel size 3 has a <span class="math notranslate nohighlight">\(3 \times 3\)</span> convolution kernel, which consists of 9 weight matrices. Some input coordinates are mapped to corresponding output coordinates with each kernel. We represent a map as a pair of lists of integers: the in map <span class="math notranslate nohighlight">\(\mathbf{I}\)</span> and the out map <span class="math notranslate nohighlight">\(\mathbf{O}\)</span>. An integer in an in map <span class="math notranslate nohighlight">\(i \in \mathbf{I}\)</span> indicates the row index of the coordinate matrix or the feature matrix of an input sparse tensor. Similarly, an integer in the out map <span class="math notranslate nohighlight">\(o \in \mathbf{O}\)</span> also indicates the row index of the coordinate matrix of an output sparse tensor. The integers in the lists are ordered in a way that k-th element <span class="math notranslate nohighlight">\(i_k\)</span> in the in map corresponds to the k-th element <span class="math notranslate nohighlight">\(o_k\)</span> of the out map. In sum, <span class="math notranslate nohighlight">\((\mathbf{I} \rightarrow \mathbf{O})\)</span> defines how the row indices of input feature <span class="math notranslate nohighlight">\(F_I\)</span> maps to the row indices of output feature <span class="math notranslate nohighlight">\(F_O\)</span>.</p>
<p>Since a single kernel map defines a map for one specific cell of a convolution kernel, a convolution requires multiple kernel maps. In the case of a <span class="math notranslate nohighlight">\(3 \times 3\)</span> convolution in this example, we need 9 maps to define a complete kernel map.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Convolution Kernel Map</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="_images/kernel_map.gif"><img alt="kernel_map" src="_images/kernel_map.gif" style="width: 100%;" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>[Photo Credit: <a class="reference external" href="https://chrischoy.org">Chris Choy</a>]</p></td>
</tr>
</tbody>
</table>
<p>In this example, we require 9 kernel maps for all <span class="math notranslate nohighlight">\(3\times 3\)</span> kernel. However, some of these kernel maps do not have elements. As the convolution kernel goes over all the coordinates, we extract kernel maps:</p>
<ul class="simple">
<li><p>Kernel B: 1 → 0</p></li>
<li><p>Kernel B: 0 → 2</p></li>
<li><p>Kernel H: 2 → 3</p></li>
<li><p>Kernel I: 0 → 0</p></li>
</ul>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="http://groups.csail.mit.edu/commit/papers/2016/parker-thesis.pdf">[1] An Investigation of Sparse Tensor Formats for Tensor Libraries, 2015</a></p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
<a href="https://github.com/NVIDIA/MinkowskiEngine">
    <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub">
</a>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-43980256-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-43980256-3');
</script>


          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tutorial/sparse_tensor_basic.html" class="btn btn-neutral float-right" title="Sparse Tensor Basics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="quick_start.html" class="btn btn-neutral float-left" title="Quick Start" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Chris Choy

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>