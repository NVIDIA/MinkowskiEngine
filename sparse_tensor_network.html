

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Sparse Tensor Networks &mdash; MinkowskiEngine 0.5.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quick Start" href="quick_start.html" />
    <link rel="prev" title="Minkowski Engine" href="overview.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> MinkowskiEngine
          

          
          </a>

          
            
            
              <div class="version">
                0.5.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Minkowski Engine</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Sparse Tensor Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#sparse-tensor">Sparse Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sparse-tensor-network">Sparse Tensor Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#generalized-convolution">Generalized Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-cases-of-generalized-convolution">Special Cases of Generalized Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="terminology.html">Definitions and Terminology</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorial/sparse_tensor_basic.html">Sparse Tensor Basics</a></li>
</ul>
<p class="caption"><span class="caption-text">Demos</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="demo/training.html">Training Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/modelnet40_classification.html">ModelNet40 Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/segmentation.html">Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/sparse_tensor_reconstruction.html">3D Sparsity Pattern Reconstruction</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/interop.html">Working with Pytorch Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/multigpu.html">Multi-GPU with Pytorch-Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo/pointnet.html">PointNet</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sparse_tensor.html">SparseTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="convolution.html">MinkowskiConvolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="pooling.html">MinkowskiPooling</a></li>
<li class="toctree-l1"><a class="reference internal" href="broadcast.html">MinkowskiBroadcast</a></li>
<li class="toctree-l1"><a class="reference internal" href="normalization.html">MinkowskiNormalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="nonlinearity.html">MinkowskiNonlinearities</a></li>
<li class="toctree-l1"><a class="reference internal" href="pruning.html">MinkowskiPruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="union.html">MinkowskiUnion</a></li>
<li class="toctree-l1"><a class="reference internal" href="coords.html">Coordinate Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">Utility Functions and Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="common.html">Miscellaneous Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="misc.html">Miscellanea</a></li>
</ul>
<p class="caption"><span class="caption-text">Miscellanea</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="issues.html">Common Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="guides.html">Guidelines for Faster Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmark</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MinkowskiEngine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Sparse Tensor Networks</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/sparse_tensor_network.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">

           <div itemprop="articleBody">
            
  <div class="section" id="sparse-tensor-networks">
<h1>Sparse Tensor Networks<a class="headerlink" href="#sparse-tensor-networks" title="Permalink to this headline">¶</a></h1>
<div class="section" id="sparse-tensor">
<h2>Sparse Tensor<a class="headerlink" href="#sparse-tensor" title="Permalink to this headline">¶</a></h2>
<p>In traditional speech, text, or image data, features are extracted densely.
Thus, the most common representations used for these data are vectors, matrices, and
tensors. However, for 3-dimensional scans or even higher-dimensional spaces,
such dense representations are inefficient as effective information occupy only a small fraction of the space. Instead, we can
only save information on the non-empty region of the space similar to how we save information on a sparse matrix.
This representation is an N-dimensional extension of a sparse matrix; thus it is known as a sparse tensor.</p>
<p>In Minkowski Engine, we adopt the sparse tensor as the basic data
representation and the class is provided as
<code class="xref py py-attr docutils literal notranslate"><span class="pre">MinkowskiEngine.SparseTensor</span></code>. Fore more information on sparse tensors
please refer to the <a class="reference external" href="terminology.html">terminology page</a>.</p>
</div>
<div class="section" id="sparse-tensor-network">
<h2>Sparse Tensor Network<a class="headerlink" href="#sparse-tensor-network" title="Permalink to this headline">¶</a></h2>
<p>Compressing a neural network to speedup inference and minimize memory footprint has been studied widely. One of the popular techniques for model compression is pruning the weights in a convnet, is also known as a <em>sparse convolutional networks</em> <a class="reference external" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Sparse_Convolutional_Neural_2015_CVPR_paper.pdf">[1]</a>. Such parameter-space sparsity used for model compression still operates on dense tensors and all intermediate activations are also dense tensors.</p>
<p>However, in this work, we focus on <em>spatially</em> sparse data, in particular, spatially sparse high-dimensional inputs and convolutional networks for sparse tensors <a class="reference external" href="https://arxiv.org/abs/1711.10275">[2]</a>. We can also represent these data as sparse tensors, and are commonplace in high-dimensional problems such as 3D perception, registration, and statistical data. We define neural networks specialized for these inputs <em>sparse tensor networks</em>  and these sparse tensor networks processes and generates sparse tensors <a class="reference external" href="https://purl.stanford.edu/fg022dx0979">[4]</a>. To construct a sparse tensor network, we build all standard neural network layers such as MLPs, non-linearities, convolution, normalizations, pooling operations as the same way we define on a dense tensor and implemented in the Minkowski Engine.</p>
</div>
<div class="section" id="generalized-convolution">
<h2>Generalized Convolution<a class="headerlink" href="#generalized-convolution" title="Permalink to this headline">¶</a></h2>
<p>The convolution is a fundamental operation in many fields. In image perception,
convolutions have been the crux of achieving the state-of-the-art performance in many tasks and
is proven to be the most crucial operation in AI, and computer vision research.
In this work, we adopt the convolution on a sparse tensor <a class="reference external" href="https://arxiv.org/abs/1711.10275">[2]</a> and propose the generalized convolution on a sparse
tensor. The generalized convolution incorporates all discrete convolutions as special cases.
We use the generalized convolution not only on the 3D
spatial axes, but on any arbitrary dimensions, or also on the temporal axis, which is proven to be more
effective than recurrent neural networks (RNN) in some applications.</p>
<p>Specifically, we generalize convolution for generic input and output coordinates, and for arbitrary kernel shapes. It allows extending a sparse tensor network to extremely high-dimensional spaces and dynamically generate coordinates for generative tasks.
Also, the generalized convolution
encompasses not only all sparse convolutions but also the
conventional dense convolutions. We list some of characteristics and applications of generalized convolution below.</p>
<ul class="simple">
<li><p>Sparse tensors for convolution kernels allow high-dimensional convolutions with specialized kernels <a class="reference external" href="https://arxiv.org/abs/1904.08755">[3]</a></p></li>
<li><p>Arbitrary input coordinates generalized convolution encompasses all discrete convolutions</p></li>
<li><p>Arbitrary output coordinates allows dynamic coordinate generation and generative networks <a class="reference external" href="https://github.com/NVIDIA/MinkowskiEngine#example-networks">[reconstruction and completion networks]</a></p></li>
</ul>
<p>Let <span class="math notranslate nohighlight">\(x^{\text{in}}_\mathbf{u} \in
\mathbb{R}^{N^\text{in}}\)</span> be an <span class="math notranslate nohighlight">\(N^\text{in}\)</span>-dimensional input feature
vector in a <span class="math notranslate nohighlight">\(D\)</span>-dimensional space at <span class="math notranslate nohighlight">\(\mathbf{u} \in \mathbb{R}^D\)</span>
(a D-dimensional coordinate), and convolution kernel weights be
<span class="math notranslate nohighlight">\(\mathbf{W} \in \mathbb{R}^{K^D \times N^\text{out} \times N^\text{in}}\)</span>.
We break down the weights into spatial weights with <span class="math notranslate nohighlight">\(K^D\)</span> matrices of
size <span class="math notranslate nohighlight">\(N^\text{out} \times N^\text{in}\)</span> as <span class="math notranslate nohighlight">\(W_\mathbf{i}\)</span> for
<span class="math notranslate nohighlight">\(|\{\mathbf{i}\}_\mathbf{i}| = K^D\)</span>. Then, the conventional dense
convolution in D-dimension is</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\text{out}}_\mathbf{u} = \sum_{\mathbf{i} \in \mathcal{V}^D(K)} W_\mathbf{i} \mathbf{x}^{\text{in}}_{\mathbf{u} + \mathbf{i}} \text{ for } \mathbf{u} \in \mathbb{Z}^D,\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{V}^D(K)\)</span> is the list of offsets in <span class="math notranslate nohighlight">\(D\)</span>-dimensional
hypercube centered at the origin. e.g. <span class="math notranslate nohighlight">\(\mathcal{V}^1(3)=\{-1, 0, 1\}\)</span>.
The generalized convolution in the following equation relaxes the above
equation.</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\text{out}}_\mathbf{u} = \sum_{\mathbf{i} \in \mathcal{N}^D(\mathbf{u}, \mathcal{C}^{\text{in}})} W_\mathbf{i} \mathbf{x}^{\text{in}}_{\mathbf{u} + \mathbf{i}} \text{ for } \mathbf{u} \in \mathcal{C}^{\text{out}}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{N}^D\)</span> is a set of offsets that define the shape of a
kernel and <span class="math notranslate nohighlight">\(\mathcal{N}^D(\mathbf{u}, \mathcal{C}^\text{in})=
\{\mathbf{i} | \mathbf{u} + \mathbf{i} \in \mathcal{C}^\text{in}, \mathbf{i}
\in \mathcal{N}^D \}\)</span> as the set of offsets from the current center,
<span class="math notranslate nohighlight">\(\mathbf{u}\)</span>, that exist in <span class="math notranslate nohighlight">\(\mathcal{C}^\text{in}\)</span>.
<span class="math notranslate nohighlight">\(\mathcal{C}^\text{in}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{C}^\text{out}\)</span> are predefined
input and output coordinates of sparse tensors. First, note that the input
coordinates and output coordinates are not necessarily the same.  Second, we
define the shape of the convolution kernel arbitrarily with
<span class="math notranslate nohighlight">\(\mathcal{N}^D\)</span>. This generalization encompasses many special cases such
as the dilated convolution and typical hypercubic kernels. Another interesting
special case is the sparse submanifold convolution when we set
<span class="math notranslate nohighlight">\(\mathcal{C}^\text{out} = \mathcal{C}^\text{in}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{N}^D
= \mathcal{V}^D(K)\)</span>. If we set <span class="math notranslate nohighlight">\(\mathcal{C}^\text{in} =
\mathcal{C}^\text{out} = \mathbb{Z}^D\)</span> and <span class="math notranslate nohighlight">\(\mathcal{N}^D =
\mathcal{V}^D(K)\)</span>, the generalized convolution on a sparse tensor becomes the conventional
dense convolution.  If we define the <span class="math notranslate nohighlight">\(\mathcal{C}^\text{in}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{C}^\text{out}\)</span> as multiples of a natural number and
<span class="math notranslate nohighlight">\(\mathcal{N}^D = \mathcal{V}^D(K)\)</span>, we have a strided dense convolution.</p>
<p>We visualize a simple 2D image convolution on a dense tensor and a sparse tensor. Note that the order of convolution on a sparse tensor is not sequential.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 48%" />
<col style="width: 52%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Dense Tensor</p></th>
<th class="head"><p>Sparse Tensor</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="_images/conv_dense.gif"><img alt="dense" src="_images/conv_dense.gif" style="width: 100%;" /></a></p></td>
<td><p><a class="reference internal" href="_images/conv_sparse.gif"><img alt="sparse" src="_images/conv_sparse.gif" style="width: 100%;" /></a></p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p>[Photo Credit: <a class="reference external" href="https://chrischoy.org">Chris Choy</a>]</p></td>
</tr>
</tbody>
</table>
<p>To efficiently compute the convolution on a sparse tensor, we must find how each non-zero element in an input sparse tensor is mapped to the output sparse tensor. We call this mapping a kernel map <a class="reference external" href="https://arxiv.org/abs/1904.08755">[3]</a> since it defines how an input is mapped to an output through a kernel. Please refer to the <a class="reference external" href="terminology.html">terminology page</a> for more details.</p>
</div>
<div class="section" id="special-cases-of-generalized-convolution">
<h2>Special Cases of Generalized Convolution<a class="headerlink" href="#special-cases-of-generalized-convolution" title="Permalink to this headline">¶</a></h2>
<p>The generalized convolution encompasses all discrete convolution as its special cases. We will go over a few special cases in this section.
First, when the input and output coordinates are all elements on a grid. i.e. a dense tensor, the generalized convolution is equivalent to regular convolution on a dense tensor.
Second, when the input and output coordinates are the coordinates of non-zero elements on a sparse tensor, the generalized convolution becomes the sparse convolution <a class="reference external" href="https://arxiv.org/abs/1711.10275">[2]</a>.
Also, when we use a hyper-cross shaped kernel <a class="reference external" href="https://arxiv.org/abs/1904.08755">[3]</a>, the generalized convolution is equivalent to the separable convolution.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Same in/out coordinates</p></th>
<th class="head"><p>Arbitrary in/out coordinates</p></th>
<th class="head"><p>Generalized Convolution</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="_images/conv_sparse_conv.gif"><img alt="sparse_conv" src="_images/conv_sparse_conv.gif" style="width: 100%;" /></a></p></td>
<td><p><a class="reference internal" href="_images/conv_sparse.gif"><img alt="sparse" src="_images/conv_sparse.gif" style="width: 100%;" /></a></p></td>
<td><p><a class="reference internal" href="_images/conv_generalized.gif"><img alt="generalized" src="_images/conv_generalized.gif" style="width: 100%;" /></a></p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>[Photo Credit: <a class="reference external" href="https://chrischoy.org">Chris Choy</a>]</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Sparse_Convolutional_Neural_2015_CVPR_paper.pdf">[1] Sparse Convolutional Neural Networks, CVPR’15</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1711.10275">[2] 3D Semantic Segmentation with Submanifold Sparse Convolutional Neural Networks, CVPR’18</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1904.08755">[3] 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks, CVPR’19</a></p></li>
<li><p><a class="reference external" href="https://purl.stanford.edu/fg022dx0979">[4] High-dimensional Convolutional Neural Networks for 3D Perception, Stanford University</a> <a class="reference external" href="https://node1.chrischoy.org/data/publications/thesis/ch4_sparse_tensor_network.pdf">Chapter 4. Sparse Tensor Networks</a></p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
<a href="https://github.com/NVIDIA/MinkowskiEngine">
    <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub">
</a>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-43980256-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-43980256-3');
</script>


          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="quick_start.html" class="btn btn-neutral float-right" title="Quick Start" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="overview.html" class="btn btn-neutral float-left" title="Minkowski Engine" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Chris Choy.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>